{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c24536c-ebb2-44fe-8390-8c892d5b929a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown(\"Process_name\",\"process_name1\",['process_name1','process_name2','process_name3'])\n",
    "dbutils.widgets.text(\"s3_location\",\"s3://tst-bkt/inbound/project_name/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63e25b98-47fc-4aaf-b623-395aca3b0c35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s3_location = dbutils.widgets.get(\"s3_location\")\n",
    "Process_name = dbutils.widgets.get(\"Process_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f2e24a7-1fb7-452d-8879-de35d66cec52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0de9d49c-02a8-46d4-bdb1-e048d05b02fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "object_list = object_name[Process_name]\n",
    "print(object_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad372a70-df8e-4cd0-b445-190070663b20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import lit, struct\n",
    "from functools import reduce\n",
    "for table_name in object_list:\n",
    "  #table_name = dbutils.widgets.get(\"table_name\")\n",
    "  print(\"table_name\", table_name)\n",
    "  s3_folder = f\"{s3_location}/{Process_name}/{table_name}/delta\"\n",
    "  #print(s3_folder)\n",
    "  folder_list = dbutils.fs.ls(s3_folder)\n",
    "  #print(folder_list[0].path)\n",
    "  folder_list.sort(reverse=True)\n",
    "  latest_folder = folder_list[0].path\n",
    "  #print(latest_folder)\n",
    "  file_list = dbutils.fs.ls(latest_folder)\n",
    "  #print(file_list)\n",
    "  for file in file_list:\n",
    "    print(file.path)\n",
    "  df = spark.read.option(\"header\", \"true\").csv(file.path, inferSchema=True, sep='|')\n",
    "  for cols in df.columns:\n",
    "    df = df.withColumnRenamed(cols, cols.replace('.', '_'))\n",
    "  datatype = df.dtypes\n",
    "  #print(datatype)\n",
    "  df2 = spark.createDataFrame(datatype, ['Field_Name', 'Data_Type']).withColumn(\"File_name\", lit(table_name))\n",
    "  df2.createOrReplaceTempView(\"s3file_metadata\")\n",
    "\n",
    "  df3 = spark.sql(f\"desc env_name.src_schema.{table_name}\")\n",
    "  src_table_name = \"src_temp_table\"\n",
    "  df3.createOrReplaceTempView(src_table_name)\n",
    "\n",
    "  df4 = spark.sql(f\"desc env_name.pub_schema.{table_name}\")  \n",
    "  pub_table_name = \"pub_temp_table\"\n",
    "  df4.createOrReplaceTempView(pub_table_name)\n",
    "\n",
    "  df5 = spark.sql(f\"\"\"select s3file_metadata.Field_Name as s3_field_name, s3file_metadata.Data_Type as s3_datatype, src_temp_table.col_name src_col_name,       \n",
    "                      src_temp_table.data_Type src_data_Type, pub_temp_table.col_name pub_col_name, pub_temp_table.data_Type src_data_Type,   \n",
    "                      case when src_temp_table.col_name = s3file_metadata.Field_Name then 'true' else 'false' end as s3_src_col,\n",
    "                      case when src_temp_table.col_name = pub_temp_table.col_name then 'true' else 'false' end as src_pub_col\n",
    "                      from s3file_metadata full outer join src_temp_table\n",
    "                      on trim(s3file_metadata.Field_Name)  = trim(src_temp_table.col_name)\n",
    "                      full outer join pub_temp_table\n",
    "                      on trim(src_temp_table.col_name)  = trim(pub_temp_table.col_name) order by s3_src_col desc\"\"\"\n",
    "                  )\n",
    "  df5.createOrReplaceTempView(\"s3_src_pub_table\")\n",
    "  df5.display()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Metadata Automation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
